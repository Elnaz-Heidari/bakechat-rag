# ğŸ BakeChat RAG â€” Retrieval-Augmented Recipe Assistant

BakeChat RAG is a mini Retrieval-Augmented Generation (RAG) application that answers recipe-related questions such as ingredient substitutions and preparation steps. It retrieves relevant recipes from a local dataset using FAISS similarity search, then uses a lightweight instruction-tuned LLM (Qwen 0.5B) to generate grounded responses with source citations. A Gradio UI provides an interactive chat-like interface.



## ğŸš€ Key Features

- âœ… FAISS-based semantic recipe retrieval  
- âœ… Detects substitution-type questions (e.g., â€œreplace egg in browniesâ€)  
- âœ… Generates answers grounded in retrieved recipes  
- âœ… Uses Qwen/Qwen2.5-0.5B-Instruct (CPU-friendly LLM)  
- âœ… Gracefully falls back to summaries when unclear  
- âœ… Gradio UI for easy interaction  
- âœ… Easily extendable to large datasets (Kaggle, RecipeNLG)



## ğŸ—ï¸ System Architecture

# ğŸ BakeChat RAG â€” Retrieval-Augmented Recipe Assistant

BakeChat RAG is a mini Retrieval-Augmented Generation (RAG) application that answers recipe-related questions such as ingredient substitutions and preparation steps. It retrieves relevant recipes from a local dataset using FAISS similarity search, then uses a lightweight instruction-tuned LLM (Qwen 0.5B) to generate grounded responses with source citations. A Gradio UI provides an interactive chat-like interface.

---

## ğŸš€ Key Features

- âœ… FAISS-based semantic recipe retrieval  
- âœ… Detects substitution-type questions (e.g., â€œreplace egg in browniesâ€)  
- âœ… Generates answers grounded in retrieved recipes  
- âœ… Uses Qwen/Qwen2.5-0.5B-Instruct (CPU-friendly LLM)  
- âœ… Gracefully falls back to summaries when unclear  
- âœ… Gradio UI for easy interaction  
- âœ… Easily extendable to large datasets (Kaggle, RecipeNLG)

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart LR
    A[User Question] --> B[Embedder<br/>SentenceTransformer (MiniLM)]
    B --> C[FAISS Index<br/>Top-K Similar Recipes]
    C --> D[Context Builder<br/>Title â€¢ Ingredients â€¢ Steps]
    D --> E[LLM Generator<br/>Qwen 0.5B Instruct]
    E --> F[Answer + Sources]
    F --> G[Gradio UI]

    classDef node fill:#fff,stroke:#111,stroke-width:1px,color:#111;
    class A,B,C,D,E,F,G node;
```

   

ğŸ“‚ Project Structure

bakechat-rag/
â”œâ”€ README.md                 # This file
â”œâ”€ requirements.txt          # Dependencies
â”œâ”€ app.py                    # Gradio UI application
â”œâ”€ Space.md                  # Notes for future Hugging Face deployment
â”œâ”€ data/
â”‚  â”œâ”€ raw/                   # Raw recipe dataset (mini JSONL demo)
â”‚  â””â”€ processed/             # FAISS index + metadata parquet
â”œâ”€ rag/
â”‚  â”œâ”€ build_index.py         # Creates FAISS index
â”‚  â”œâ”€ query.py               # Retrieval + generation logic
â”‚  â””â”€ eval_retrieval.py      # Optional evaluation script
â””â”€ prompts/
   â””â”€ system.txt             # System prompt instructions



âš™ï¸ How the RAG Pipeline Works
Stage	What Happens
ğŸ”¹ Embedding	Query converted to vector via MiniLM
ğŸ”¹ Retrieval	FAISS fetches top-matching recipes
ğŸ”¹ Context Build	Title, ingredients, steps merged
ğŸ”¹ Intent Check	Detects substitution questions
ğŸ”¹ Generation	Qwen LLM produces concise response
ğŸ”¹ Citation	Sources appended as [Title | ID]




## ğŸ¥ Quick Demo

![BakeChat RAG UI](assets/demo.png)



âœ… Quickstart (Local Demo)

    Requires Python 3.10+ and PowerShell/macOS/Linux terminal.

1) Setup virtual environment
python -m venv .venv
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

2) Install dependencies
pip install -r requirements.txt

3) Add a dataset
    âœ… Ready to run: A demo dataset (mini_recipes.jsonl) is already included in data/raw/, so you can run the app immediately.
    ğŸ“ˆ To scale up later, replace it with a larger dataset (e.g., Kaggle Food.com or a RecipeNLG subset) and rebuild the FAISS index.

4) Build the FAISS index
python rag/build_index.py --input data/raw/mini_recipes.jsonl --format jsonl

5) Launch the Gradio app
python app.py

Then open: http://127.0.0.1:7860
âš ï¸ First run will download the generator model (Qwen/Qwen2.5-0.5B-Instruct) automatically (~1 GB). Subsequent runs use the local cache.



âœ… First-Run Checklist

Python 3.10+ installed

Created and activated a virtual environment

pip install -r requirements.txt completed

Built the FAISS index with your dataset

Aware the model will download (~1 GB) the first time

Ran python app.py and opened the Gradio UI


ğŸ’¬ Example Queries
| Query                             | Expected Behavior            |
| --------------------------------- | ---------------------------- |
| â€œReplace eggs in browniesâ€        | Bullet-style substitutions   |
| â€œHow to make vegan mayonnaise?â€   | Summarizes steps             |
| â€œGluten-free pizza dough method?â€ | Extracts instructions        |
| â€œAlternative to milk in pancakesâ€ | Suggests liquid replacements |



ğŸ§  Models Used
| Component           | Model                                  |
| ------------------- | -------------------------------------- |
| Embedder            | sentence-transformers/all-MiniLM-L6-v2 |
| Generator (default) | Qwen/Qwen2.5-0.5B-Instruct             |
| Optional Reranker   | cross-encoder/ms-marco-MiniLM-L-6-v2   |



ğŸ“Š Dataset

    âœ… Current: 5-item demo JSONL

    ğŸ“ˆ Ready for scaling using Kaggle/RecipeNLG datasets

    ğŸ’¡ No pipeline changes required â€” just rebuild index after replacing the dataset.




ğŸ“… Roadmap
| Status | Task                                |
| ------ | ----------------------------------- |
| âœ…     | Build working RAG demo              |
| ğŸ”œ     | Add `--limit` support to indexing   |
| ğŸ”œ     | Scale to partial Kaggle dataset     |
| ğŸ”œ     | Optional reranker toggle by default |
| ğŸš€     | Deploy to Hugging Face Spaces       |




ğŸ‘©â€ğŸ’» Author

Crafted by Elnaz as part of an LLM learning journey exploring real-world RAG architectures.


ğŸ“„ License

MIT License â€“ feel free to fork, learn, and extend!
