# ğŸ BakeChat RAG â€” Retrieval-Augmented Recipe Assistant

BakeChat RAG is a mini Retrieval-Augmented Generation (RAG) application that answers recipe-related questions such as ingredient substitutions and preparation steps. It retrieves relevant recipes from a local dataset using FAISS similarity search, then uses a lightweight instruction-tuned LLM (Qwen 0.5B) to generate grounded responses with source citations. A Gradio UI provides an interactive chat-like interface.

---

## ğŸš€ Key Features

- âœ… FAISS-based semantic recipe retrieval  
- âœ… Detects substitution-type questions (e.g., â€œreplace egg in browniesâ€)  
- âœ… Generates answers grounded in retrieved recipes  
- âœ… Uses Qwen/Qwen2.5-0.5B-Instruct (CPU-friendly LLM)  
- âœ… Gracefully falls back to summaries when unclear  
- âœ… Gradio UI for easy interaction  
- âœ… Easily extendable to large datasets (Kaggle, RecipeNLG)

---

## ğŸ—ï¸ System Architecture
```mermaid
flowchart LR
  A["User Question"] --> B["Embedder (MiniLM)"]
  B --> C["FAISS Index (Top-K Similar Recipes)"]
  C --> D["Context Builder (title, ingredients, steps)"]
  D --> E["LLM Generator (Qwen 0.5B)"]
  E --> F["Answer + Sources"]
  F --> G["Gradio UI"]
```



# ğŸ“‚ Project Structure    
```text
bakechat-rag/
â”œâ”€ README.md                 # This file
â”œâ”€ Makefile                  # One-command setup, index build, run
â”œâ”€ requirements.txt          # Dependencies
â”œâ”€ app.py                    # Gradio UI application
â”œâ”€ Space.md                  # Notes for future Hugging Face deployment
â”œâ”€ data/
â”‚  â”œâ”€ raw/                   # Raw recipe dataset (demo JSONL)
â”‚  â”‚  â””â”€ recipes.jsonl
â”‚  â””â”€ processed/             # FAISS index + metadata (generated; gitignored)
â”œâ”€ rag/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ build_index.py         # Creates FAISS index
â”‚  â”œâ”€ query.py               # Retrieval + generation logic
â”‚  â””â”€ eval_retrieval.py      # Optional evaluation script
â”œâ”€ prompts/
â”‚  â””â”€ system.txt             # System prompt instructions
â””â”€ assets/
   â””â”€ ui-screenshot.png      # Static UI screenshot (optional)
```


# Quickstart (3 commands)

Requires Python 3.10+ and a terminal (PowerShell on Windows or any Unix shell).

git clone https://github.com/<your-username>/bakechat-rag.git
cd bakechat-rag

# 1) Create venv + install deps
make install

# 2) Build FAISS index from the demo dataset
make build-index

# 3) Launch the Gradio app
make run


Then open the link printed in the terminal (usually http://127.0.0.1:7860).

ğŸ’¡ First run will download models. Subsequent runs are instant thanks to local caching.

# Optional: keep model caches inside the repo

Set a local Hugging Face cache so models live under .cache/huggingface in this project:

- Windows (PowerShell): setx HF_HOME ".cache\huggingface"
Close and reopen your terminal afterward.

- macOS/Linux: export HF_HOME=.cache/huggingface

# ğŸ› ï¸ Makefile Targets

| Command            | Description                                                           |
| ------------------ | --------------------------------------------------------------------- |
| `make install`     | Create venv and install dependencies                                  |
| `make build-index` | Build FAISS index from `data/raw/recipes.jsonl` into `data/processed` |
| `make run`         | Start the Gradio app (`app.py`)                                       |
| `make refresh`     | Delete `data/processed/` and rebuild the index                        |
| `make lint`        | Ruff lint (if added to `requirements-dev.txt`)                        |
| `make format`      | Black format (if added to `requirements-dev.txt`)                     |
| `make test`        | Run tests if `tests/` exists                                          |
| `make clean`       | Remove Python and tool caches                                         |
                                      |

# Customize input format/file if needed:
make build-index INPUT_FILE=data/raw/recipes.jsonl INPUT_FMT=jsonl



# âš™ï¸ How the RAG Pipeline Works
| Stage            | What Happens                         |
| ---------------- | ------------------------------------ |
| ğŸ”¹ Embedding     | Query converted to vector via MiniLM |
| ğŸ”¹ Retrieval     | FAISS fetches top-matching recipes   |
| ğŸ”¹ Context Build | Title, ingredients, steps merged     |
| ğŸ”¹ Intent Check  | Detects substitution questions       |
| ğŸ”¹ Generation    | Qwen LLM produces concise response   |
| ğŸ”¹ Citation      | Sources appended as `[Title \| ID]`  |


# ğŸ’¬ Example Queries
Query	Expected Behavior
â€œReplace eggs in browniesâ€	Bullet-style substitutions
â€œHow to make vegan mayonnaise?â€	Summarizes steps
â€œGluten-free pizza dough method?â€	Extracts instructions
â€œAlternative to milk in pancakesâ€	Suggests liquid replacements


# ğŸ§  Models Used
Component	Model
Embedder	sentence-transformers/all-MiniLM-L6-v2
Generator (default)	Qwen/Qwen2.5-0.5B-Instruct
Optional Reranker	cross-encoder/ms-marco-MiniLM-L-6-v2


# ğŸ“Š Dataset

    âœ… Current: demo JSONL at data/raw/recipes.jsonl

    ğŸ“ˆ Ready to scale to Kaggle/RecipeNLG subsets (replace the file, then run make refresh or make build-index)

# Input format:
newline-delimited JSON (.jsonl) with per-recipe fields that your indexer expects (e.g., title, ingredients, steps, id). No pipeline code changes required when you swap in a larger file; just rebuild the index.

# ğŸ§ª Sanity Checks
- Python 3.10+ available
- Virtual environment created (.venv/)
- Index built successfully in data/processed/
- First run downloads models; later runs start immediately
- App reachable at the printed local URL
If imports fail for rag.*, ensure you run commands from the repo root and that rag/__init__.py exists.

# ğŸ—ºï¸ Roadmap
| Status | Task                                |
| ------ | ----------------------------------- |
| âœ…     | Working RAG demo              |
| ğŸ”œ     | Add `--limit` to indexer   |
| ğŸ”œ     | Scale to partial Kaggle dataset     |
| ğŸ”œ     | Optional reranker toggle |
| ğŸš€     | Deploy to Hugging Face Spaces       |


# ğŸ‘©â€ğŸ’» Author

Crafted by Elnaz as part of an LLM learning journey exploring real-world RAG architectures.


# ğŸ“„ License

MIT License â€“ feel free to fork, learn, and extend!